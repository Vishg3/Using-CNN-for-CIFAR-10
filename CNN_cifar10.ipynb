{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74094f39-6b8a-419d-9dd8-a95aab668ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367c72d0-3dd9-4432-9fcb-5d8080d91177",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_imgs,train_labels),(test_imgs,test_labels)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc323d3f-6e4a-42d4-932f-f9c4c20807ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs,test_imgs=train_imgs/255.0,test_imgs/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a106868-8515-4a6c-ad38-ed68513157ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 11:45:11.892770: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.050918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.050953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.055586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.055621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.055636: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.145031: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.145076: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.145082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-01-28 11:45:12.145108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 11:45:12.145126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(16,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(16,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbe22466-c3a5-4f0a-a2f8-bb675da0c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 16)          2320      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10250 (40.04 KB)\n",
      "Trainable params: 10250 (40.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fb61cf-e52a-442a-a6c7-1c931429370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1984ca6d-dbb3-48f4-bfef-d4684e3b95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125c71fb-eaec-4322-bab5-43544aff3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 11:51:48.918659: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2025-01-28 11:51:49.132460: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2025-01-28 11:51:49.132490: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2025-01-28 11:51:49.132577: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2025-01-28 11:51:49.681420: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.825725: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.825779: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.826005: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.826510: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.826569: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.826662: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.827542: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.828018: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:49.828817: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-01-28 11:51:50.072498: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f9ce83496a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-01-28 11:51:50.072526: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-01-28 11:51:50.094804: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-28 11:51:50.158974: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:408] Couldn't read CUDA driver version.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738045310.171221    3547 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 7s 21ms/step - loss: 2.1584 - accuracy: 0.1826 - val_loss: 1.9326 - val_accuracy: 0.2811\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.9063 - accuracy: 0.2791 - val_loss: 1.7786 - val_accuracy: 0.3433\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.7987 - accuracy: 0.3222 - val_loss: 1.6975 - val_accuracy: 0.3758\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.7219 - accuracy: 0.3595 - val_loss: 1.6021 - val_accuracy: 0.4190\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.6413 - accuracy: 0.3941 - val_loss: 1.5504 - val_accuracy: 0.4343\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.5819 - accuracy: 0.4171 - val_loss: 1.4839 - val_accuracy: 0.4565\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.5356 - accuracy: 0.4354 - val_loss: 1.4555 - val_accuracy: 0.4738\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.5092 - accuracy: 0.4443 - val_loss: 1.4181 - val_accuracy: 0.4843\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.4839 - accuracy: 0.4587 - val_loss: 1.4093 - val_accuracy: 0.4850\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.4571 - accuracy: 0.4641 - val_loss: 1.3796 - val_accuracy: 0.4987\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.4447 - accuracy: 0.4735 - val_loss: 1.3587 - val_accuracy: 0.5080\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.4175 - accuracy: 0.4815 - val_loss: 1.3372 - val_accuracy: 0.5169\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.4037 - accuracy: 0.4878 - val_loss: 1.3648 - val_accuracy: 0.4959\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3989 - accuracy: 0.4900 - val_loss: 1.3207 - val_accuracy: 0.5253\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3761 - accuracy: 0.5015 - val_loss: 1.3081 - val_accuracy: 0.5278\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3668 - accuracy: 0.5065 - val_loss: 1.2960 - val_accuracy: 0.5362\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.3550 - accuracy: 0.5096 - val_loss: 1.3014 - val_accuracy: 0.5345\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3485 - accuracy: 0.5115 - val_loss: 1.2817 - val_accuracy: 0.5394\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3255 - accuracy: 0.5211 - val_loss: 1.2961 - val_accuracy: 0.5374\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3294 - accuracy: 0.5210 - val_loss: 1.2569 - val_accuracy: 0.5497\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3154 - accuracy: 0.5256 - val_loss: 1.2534 - val_accuracy: 0.5496\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3020 - accuracy: 0.5298 - val_loss: 1.2683 - val_accuracy: 0.5407\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2978 - accuracy: 0.5305 - val_loss: 1.2458 - val_accuracy: 0.5523\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2942 - accuracy: 0.5316 - val_loss: 1.2313 - val_accuracy: 0.5592\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2767 - accuracy: 0.5414 - val_loss: 1.2273 - val_accuracy: 0.5658\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2753 - accuracy: 0.5374 - val_loss: 1.2809 - val_accuracy: 0.5477\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2696 - accuracy: 0.5435 - val_loss: 1.2077 - val_accuracy: 0.5694\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2605 - accuracy: 0.5456 - val_loss: 1.2153 - val_accuracy: 0.5640\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2567 - accuracy: 0.5470 - val_loss: 1.1967 - val_accuracy: 0.5764\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2497 - accuracy: 0.5497 - val_loss: 1.1969 - val_accuracy: 0.5730\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2425 - accuracy: 0.5527 - val_loss: 1.1950 - val_accuracy: 0.5696\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2358 - accuracy: 0.5572 - val_loss: 1.1884 - val_accuracy: 0.5802\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2263 - accuracy: 0.5597 - val_loss: 1.1987 - val_accuracy: 0.5718\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2211 - accuracy: 0.5606 - val_loss: 1.1811 - val_accuracy: 0.5764\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2099 - accuracy: 0.5639 - val_loss: 1.1780 - val_accuracy: 0.5803\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.2022 - accuracy: 0.5654 - val_loss: 1.1502 - val_accuracy: 0.5944\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 1.1976 - accuracy: 0.5694 - val_loss: 1.1676 - val_accuracy: 0.5853\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.1983 - accuracy: 0.5682 - val_loss: 1.1569 - val_accuracy: 0.5899\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.1860 - accuracy: 0.5746 - val_loss: 1.1709 - val_accuracy: 0.5824\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_imgs,train_labels,epochs=100,batch_size=512,callbacks=[es],validation_data=(test_imgs,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9d5669-8d5e-46d2-9a66-1f4a316eb9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred=model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79ac860-05c2-40ac-90e9-83466e1725d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=(test_pred>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53c57d47-baf2-45b7-9d3d-c878eafafe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1502 - accuracy: 0.5944\n",
      "test_loss: 1.1501590013504028\n",
      "test_accuracy: 0.5943999886512756\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(test_imgs,test_labels)\n",
    "print('test_loss:',test_loss)\n",
    "print('test_accuracy:',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccb6f941-d9d2-45dc-83a5-0e31d156a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1065 - accuracy: 0.6046\n",
      "train_loss: 1.1065428256988525\n",
      "train_accuracy: 0.6045799851417542\n"
     ]
    }
   ],
   "source": [
    "train_loss,train_accuracy=model.evaluate(train_imgs,train_labels)\n",
    "print('train_loss:',train_loss)\n",
    "print('train_accuracy:',train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7e59f3-01ee-4f84-8b62-73dcde2c018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is generalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
